# ğŸ•·ï¸ Web Scraper Project

A Python web scraper for extracting product data from e-commerce websites. This project demonstrates advanced web
scraping techniques including **pagination handling**, **dynamic content parsing** with Selenium, **error management**,
and **data export** to CSV. Built with **requests**, **BeautifulSoup4**, **Selenium**, and Python's standard libraries.

## ğŸš€ Features

- **Product Data Extraction**: Collect comprehensive product information (title, description, price, rating, reviews)
- **Dynamic Content Handling**: Parse JavaScript-rendered content using Selenium
- **Configuration Price Parsing**: Extract prices for different product configurations
- **Pagination Support**: Automatically handle multi-page product listings
- **Error Handling**: Robust error management and logging system
- **CSV Export**: Save scraped data to structured CSV format
- **Session Management**: Efficient HTTP requests with session reuse

## ğŸ› ï¸ Technology Stack

- **Python** - Core programming language
- **BeautifulSoup4** - HTML parsing library
- **Requests** - HTTP request handling
- **Selenium** - Dynamic content automation
- **Fake UserAgent** - User-Agent rotation for requests
- **Logging** - Application logging system
- **Dataclasses** - Modern Python data structures

## ğŸ“ Project Structure

```
web_scraper_group_6/
â”‚
â”œâ”€â”€ .venv/                     # Virtual environment
â”‚
â”œâ”€â”€ src/                       # Source code directory
â”‚   â”œâ”€â”€ main.py                # Entry point with WebDriver initialization
â”‚   â”œâ”€â”€ scraper.py             # Web scraping logic with Selenium integration
â”‚   â”œâ”€â”€ models.py              # Data models with additional_info field
â”‚   â””â”€â”€ utils/                 # Utility modules
â”‚       â”œâ”€â”€ logger.py          # Logging configuration
â”‚       â”œâ”€â”€ file_handlers.py   # File operations
â”‚       â””â”€â”€ selenium_utils.py  # WebDriver utilities
â”‚
â”œâ”€â”€ data/                      # Data output directory
â”‚   â””â”€â”€ products.csv           # Scraped products data
â”‚
â”œâ”€â”€ logs/                      # Application logs
â”‚   â””â”€â”€ parser.log             # Application log file
â”‚
â”œâ”€â”€ requirements.txt           # Project dependencies
â””â”€â”€ README.md                  # Project documentation
```

## ğŸ“¦ Installation

1. Clone the repository:

```bash
git clone <repository-url>
cd web_scraper_group_6
```

2. Create and activate virtual environment:

```bash
python -m venv .venv
source .venv/bin/activate  # Linux/Mac
# or
.venv\Scripts\activate     # Windows
```

3. Install dependencies:

```bash
pip install -r requirements.txt
```

## ğŸ¯ Usage

Run from project root directory:

```bash
python -m src.main
```

## ğŸ“Š Output

- **Scraped Data**: Saved to `data/products.csv`
- **Application Logs**: Stored in `logs/parser.log`
- **Product Information**: Includes dynamic configuration prices

## ğŸ”§ Educational Purpose

> ğŸ“¦ This project is designed for **educational purposes**. Initially implemented in a **single file** for functionality
> testing, students are tasked with **structuring** the complete code by distributing it across appropriate
> **directories** and **modules** according to the defined project architecture.

## ğŸ“„ License

This project is created for educational purposes. Please use responsibly and respect website terms of service.

## ğŸ¤ Contributing

Feel free to submit issues and enhancement requests!